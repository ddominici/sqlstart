---
title: "Elenco sessioni"
weight: 6
header_menu: true
---

#### Keynote

üïú 09:00 @ A9/A10

‚≠êÔ∏è ANALYTICS IN THE ERA OF AI [ITA] - Andrea Benedetti (Microsoft)

Nel panorama tecnologico - ancora pi√π in rapida evoluzione rispetto al solito - l'analisi dei dati √® sempre di pi√π la chiave di volta per poter realizzare con successo processi decisionali informati
Con l'avvento dell'intelligenza artificiale, inoltre, la richiesta di piattaforme che possano integrarsi perfettamente con le ultime funzionalit√† non √® mai stata cos√¨ grande
L'obiettivo delle ultime tecnologie √® proprio quello di aiutare ogni organizzazione a sfruttare tutto il potenziale dei propri dati, consentendo di sfruttare la potenza dell'intelligenza artificiale generativa rispetto ai propri patrimoni informativi e aiutando gli utenti aziendali a trovare informazioni e trarre valore in maniera facile e rapida.

---

#### Sessioni da 60 minuti

üïú 10:00 @ A9/A10

‚≠êÔ∏è ESTRARRE I DATI UTILIZZANDO L'AI: AZURE OPENAI VS DOCUMENT INTELLIGENCE! [ITA] - Massimo Bonanni

GPT e' probabilmente la buzz-word del momento: tutti la citano e tutti usano i modelli della famiglia GPT per creare contenuti fantastici. Ma quanti di voi sanno che i modelli Generative (la G dell'acronimo precedente) possono essere utilizzati anche per estrarre dati da documenti (e non solo crearli)? E che esistono anche altri modi per ottenere lo stesso risultato senza diventare esperti di prompt engineering? In questa sessione, vedremo due tools Microsoft diametralmente opposti per fare estrazioni dati con le loro peculiarita' e i loro svantaggi. Azure OpenAI con i suoi modelli GPT e Document Intelligence con il suo approccio classico basato sul training di modelli custom pensati per analizzare documenti. Chi si aggiudichera' la sfida? Venite a scoprirlo!

---

üïú 10:00 @ B1

‚≠êÔ∏è CALCULATE - LA REGINA DELLE FUNZIONI DAX [ITA] - Francesco Bergamaschi

CALCULATE √® la funzione DAX pi√π potente in quanto consente di manipolare a proprio piacimento il contesto dei filtri, come nel caso dei calcoli time-intelligence. Tuttavia, la funzione non √® facile da capire a meno che il suo intero algoritmo non sia completamente chiaro. In questa sessione verr√† spiegato l'algoritmo insieme ad una serie di esempi di complessit√† crescente con l'obiettivo di raggiungere una comprensione completa, ma guidata e graduale, della funzione CALCULATE.

---

üïú 10:00 @ B2

‚≠êÔ∏è CHATGPT IS THE BEST DBA SIDEKICK [ENG]- Rudi Bruchez

Have you tried using ChatGPT to ease your day-to-day database duties? ChatGPT is your AI partner that can read deadlock graphs, analyze locking, write and correct T-SQL code, interpret execution plans, find informations from the ERRORLOG, and much more. I'm going to introduce you to the assistant every DBA wishes they had - OpenAI's language model, ChatGPT. We're going to look at the impressive, the surprising, and even the funny hiccups when AI meets SQL Server.
Some Highlights:
Ever feel like you're trying to decode alien language when looking at deadlock graphs? Watch as ChatGPT deciphers these for you in real-time!
AI Locking Analysis: see ChatGPT detect and analyze locking conflicts from the unfathomable blocked process report
Ask ChatGPT for any T-SQL solution for getting information or acting on the Database, like creating test data. And correct its mistakes along the way.
AI Reading Execution Plans: Watch ChatGPT unravel the mysteries of execution plans, a task that often seems like trying to understand modern art!
In this session, you will understand the potential (and limits!) of AI, specifically ChatGPT, in SQL Server administration and performance tuning, and learn to leverage ChatGPT in diagnosing and resolving common and not-so-common SQL Server issues, including those pesky deadlock graphs and locking issues.
By the way, thanks to ChatGPT for the help in writing this abstract!

---

üïú 10:00 @ B3

‚≠êÔ∏è THE MICROSOFT FABRIC TOUR IN 80 COPILOT PROMPTS [ITA] - Marco Englaro

Unlock the full potential of your data
Supercharge Productivity
Let AI summarize actions for you, and optimize your time
Uplevel Skills
Be better at what you‚Äôre good at and master what you‚Äôve yet to learn
Discover Insights
Harness the power of AI so you never have to start from scratch

---

üïú 11:15 @ A9/A10

‚≠êÔ∏è COME L'AI PU√í AIUTARE NELLA DATA GOVERNANCE [ITA] - Franco Perduca

La Data Governance la si pu√≤ attuare come la definizione delle regole e il controllo sulla gestione dei dati, in termini di pianificazione, esecuzione e monitoraggio (dama.org)
In questa sessione vedremo come l'AI pu√≤ aiutarci nella ricostruzione dei flussi dei dati e come esporre al meglio le informazioni disponibili in una organizzazione e delle entit√† di business e tecnologiche ad esse connesse.
In tutto utilizzando anche Microsoft Purview

---

üïú 11:15 @ B1

‚≠êÔ∏è MICROSOFT FABRIC PER L'IOT (E NON SOLO) [ITA] - Marco Parenzan

Fabric rappresenta una complessa e ricca evoluzione della piattaforma di analytics di Microsoft in Azure. In particolare in questa sessione ci concentreremo su come questa gestisca i tipici dati dell'IoT, ovvero i real-time data e i dati non strutturati, ma ovviamente capiremo anche che non sono utili solo in questo scenario.

---

üïú 11:15 @ B2

‚≠êÔ∏è SQL SERVER UNIT TESTING CON TSQLT, DOCKER E GITHUB ACTIONS [ITA] - Sergio Govoni

Le unit di test sviluppate per uno o pi√π oggetti SQL Server non hanno il solo scopo di verificare che siano stati soddisfatti i requisiti una volta, prima del rilascio; il vero game changer √® rappresentato dalla possibilit√† di ripetere le verifiche durante lo sviluppo di nuovo codice e durante la correzione di bug. La ripetibilit√† dei test fornisce la possibilit√† di automatizzarli, condizione essenziale per integrare test automatici all'interno di uno strumento di Continuous Integration. In questa sessione, ricca di demo, verr√† descritto come automatizzare il test di uno o pi√π oggetti SQL Server utilizzando tSQLt, Docker e GitHub Action!

---

üïú 11:15 @ B3

‚≠êÔ∏è FABRIC - END TO END SCENARIO [ENG] - Luca Ferrari, Anu Singh

Onelake, workspace, delta format, shortcuts, lakehouse, and warehouse, and then spark, T-SQL, or data flow, or pipeline. Then Semantic model and PowerBI. In this demo-based session, we will delve into the details of creating an analytical solution with MS Fabric, leveraging some of its (several) features.

---

üïú 14:00 @ A9/A10

‚≠êÔ∏è RAG AND GENERATIVE AI FOR THE DATA PROFESSIONAL [ITA] - Emanuele Meazzo

GPT? RAG? Embeddings? CHUNKING?!? What are all these new words and acronyms?
Don't worry, in this session, aimed to the data professional that has worked with SQL Databases up until now, we'll explain all the basics of the modern AI architecture, from foundational models to RAG, explaining why you need a Vector Database now and what does it even do!
At the end of the session, you'll finally say: "Now it makes sense!"

---

üïú 14:00 @ B1

‚≠êÔ∏è ALLSELECTED: COS'√à E COME FUNZIONA - David Bianconi

Percorso ragionato alla scoperta di una delle funzioni pi√π complesse del linguaggio DAX

---

üïú 14:00 @ B2

‚≠êÔ∏è HOW TO SAVE THE PLAN CACHE [ITA] -  Alessandro Mortola

This session will start from the analysis of the Plan Cache structure in Sql Server and its limits. After that, we will evaluate the impact on the Plan Cache of both the Parameterized and the Ad-hoc queries. We will explain all the different techniques for parameterizing and end up showing what the Parameter Sniffing is and how Sql Server 2022 tries to solve it introducing the Parameter Sensitive Plan optimization.
In the second part of the session we will analyze some configuration settings that we can set whenever the Ad-hoc queries become a problem: the "Simple and Forced Parameterization" and the "Optimize for Ad-hoc workload".

üïú 14:00 @ B3
‚≠êÔ∏è FABRIC: I LOVE YOU, I LOVE YOU NOT
On May '23 data professionals from all around the globe felt like a kid on Christmas day eager to unbox the new toy: Microsoft Fabric.
The new kid of the block generated a lot of reactions on the internet, and Fabric became the only topic to speak of.
Anyway, being a consultant obliges not to be overwhelmed by the hype and to study a product carefully in order to tailor solution on customer needs.
Moreover Fabric is not a tool it's an entire ecosystem.
Studying Fabric for more than one year, since private preview, I had the possibility to see aspects that I truly love (the concept of "The Great Unifier", Direct Lake, Shortcuts and more), but I also found things that I don't like and should be improved IMHO (few artifacts supported by CI/CD, different behaviors on Delta tables according to the workload, busting and smoothing like a black box and more).
In this session I'll try to show you many different aspects that I loved and I hated explaining pros and cons and how I would apply them in a real world scenario.
I won't expect participants to find answers in this session, I expect them to find the right questions :-).
üôÇ Riccardo Perico

üïú 15:15 @ A9/A10
‚≠êÔ∏è SIMPLIFYING CHATGPT: EFFICIENT DOCUMENT QUERYING WITH AZURE OPENAI
This session aims to demystify ChatGPT for a broad audience, highlighting its integration with Azure OpenAI for effective document querying. We'll cover the basics of ChatGPT, its language model, and how to set it up in Azure, focusing on usability, data security, and compliance. Real-world examples will demonstrate its practical applications in extracting insights from data, with the goal of equipping attendees with the knowledge to effectively use ChatGPT in various scenarios.
üôÇ Luca Zavarella

üïú 15:15 @ B1
‚≠êÔ∏è AZURE SQL NETWORKING SECRETS
Provisioning an Azure SQL DB is very easy, but are the default configurations good for you? How to ensure our database is really safe? Come to this session to discover this and a lot more
üôÇ Dennes Torres

üïú 15:15 @ B2
‚≠êÔ∏è DIMOSTRA LA TUA ABILIT√Ä E OTTIENI IL GIUSTO RICONOSCIMENTO CON LE CREDENZIALI MICROSOFT
Lavori sui dati tutto il giorno? A furia di dare martellate conosci i meandri pi√π nascosti di Azure?
Forse √® il caso di valutare prendere una credenziale Microsoft, per soddisfazione personale e per mettere qualcosa di interessante sul profilo LinkedIn e nel CV!
La formazione oggigiorno √® una tematica fondamentale, sia dal punto di vista aziendale che per il singolo: il mondo IT √® in costante evoluzione e bisogna rimanere "sul pezzo" sempre e comunque.
Inizieremo un viaggio di 60 minuti attraverso il panorama delle certificazioni Microsoft, con un‚Äôattenzione particolare all‚Äôarea dei dati. Vedremo dove trovare il materiale sul quale prepararsi e qualche tips & tricks per affrontare l'esame con maggiore tranquillit√†.
Introdurremo anche il mondo delle Applied Skills, le nuove credenziali che ti permettono di dimostrare dal punto di vista pratico il livello di preparazione su una tematica verticale. Un ottimo modo per spendere un paio d'ore del proprio tempo, e portarsi a casa un attestato da inserire nel proprio profilo.
Non mancare!
üôÇ Marco Obinu

üïú 15:15 @ B3
‚≠êÔ∏è MICROSOFT FABRIC: LICENSING DEMYSTIFIED
Microsoft Fabric Free, Power BI Pro, PPU, Premium, Capacity...Fin da quando esiste Power BI, ho sempre riscontrato da parte dei clienti una certa difficolt√† (comprensibile) ad orientarsi nel mondo del licensing. L'avvento di Fabric, il quale ha inglobato ed esteso notevolmente l'ecosistema di Power BI, ha aggiunto un paio di strati di complessit√† allo scenario, rendendo ancora pi√π arduo stilare una lista della spesa delle licenze necessarie.
In questa sessione cercheremo di mettere in fila alcuni concetti architetturali chiave per rispondere a domande ricorrenti:
- Cos'√® Microsoft Fabric?
- Qual √® il suo rapporto con Power BI?
- Di quali licenze potrei aver bisogno per utilizzarlo al meglio?
üôÇ Francesco Milano

üïú 16:30 @ B1
‚≠êÔ∏è SQL PER TIME-SERIES DATA: QUESTDB
E se ti dicessi che esiste un database open source che ti permette di fare query tramite Sql su time series e che addirittura implementa alcune funzionalit√† appositamente per manipolare questi tipi di dati? Ti presento QuestDB: un database super ottimizzato per time-series data che grazie ad alcune sql extensions permette diverse operazioni su questi tipi di dati. In questa sessione scopriremo prima cosa c'√® sotto il cofano di QuestDB e poi vedremo alcune delle sue sql extensions imparando a giocare con i dati time-series senza dover imparare nulla che gi√† non conosciamo: SQL
üôÇ Riccardo Solazzi

üïú 16:30 @ B2
‚≠êÔ∏è ARCHITETTURE DATI COMPLESSE E DOVE TROVARLE
Vi √® mai capitato di dover replicare i dati dal vostro gestionale per poi esporli verso clienti o fornitori, magari usando delle REST API? E se i due database sono diversi? E se ho diversi soggetti che devono potersi autenticare con Entra ID, ovviamente con privilegi diversi? No? Beh, questa √® la sessione per voi! Vedremo come creare un architettura dati che replica da SQL Server a PostgreSQL (on-prem o in cloud, indifferente) ed espone i dati via Data API Builder in una manciata di secondi utilizzando Docker.
üôÇ Danilo Dominici

üïú 16:30 @ B3
‚≠êÔ∏è MISURAZIONE DELLE PERFORMANCE DEI PUNTI VENDITA MEDIANTE MACHINE LEARNING, IL CASO RETAILOR
Frutto della collaborazione tra il Dipartimento di Management UNIVPM, Selda srl eLIVE srl, RetailOR rappresenta la soluzione di Machine Learning e Data Science per analizzare le performance dei punti vendita esistenti e lo sviluppo di quelli nuovi. Questo framework √® stato sviluppato a partire dalle esigenze di una realt√† del mondo del commercio e adotta l‚Äôapproccio tipico dei progetti di data science che unisce l‚Äôaspetto funzionale e quello tecnico. Nello specifico, parte da uno studio economico-funzionale del settore di riferimento con l‚Äôobiettivo di individuare tutte levariabili che potrebbero rappresentare dei fattori in grado di spiegare la variabilit√† nelle performance dei singoli punti vendita. Terminata la fase della scelta delle variabili, prende avvio quella della normalizzazione e dell‚Äôanalisi delle correlazioni per ridurre la possibilit√† di ridondanza informativa e di overfitting. Su questo nuovo dataset, vengono quindi applicati algoritmi non supervisionati (es. K-means, DBSCAN, ‚Ä¶) per individuare il numero e la tipologia di cluster pi√π efficaci in cui dividere i punti vendita. Infine, dopo aver selezionato gli indicatori pi√π adatti nel singolo caso specifico per distinguere punti vendita performanti da quelli non, vengono implementati diversi algoritmi di supervised learning (es. Random Forest, Linear Discriminant Analysis, SVC, Logistic Regression, ...) per andare a classificare i miei punti vendita sulla base di questi indicatori e delle feature selezionate. L‚Äôadozione di diverse metriche di accuratezza ed efficacia permette di suggerire l‚Äôalgoritmo migliore tra quelli adottati e all‚Äôinterno di quella metodologia vengono evidenziate le variabili che pi√π di tutte hanno contribuito al processo di classificazione, risultando determinanti e quindi da monitorare nel tempo. In definitiva, RetailOR rappresenta un‚Äôefficace soluzione per comprendere le similitudini, e fare comparazioni e benchmarking nel mondo retail; inoltre, permette di individuare le variabili che pi√π influenzano la performance, per favorire miglioramenti e risultati, fissazione dei target e apertura di nuovi punti vendita.
üôÇ Alessio Giorgetti, Danilo Scarponi
